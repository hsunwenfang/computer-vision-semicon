{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7530774c",
   "metadata": {},
   "source": [
    "# Computer Vision Semiconductor Analysis - Interactive Notebook\n",
    "\n",
    "This notebook provides an interactive exploration of the computer vision pipeline for semiconductor analysis using MLX GPU acceleration.\n",
    "\n",
    "## Features Covered:\n",
    "1. Synthetic image generation with geometric patterns\n",
    "2. GPU-accelerated image processing\n",
    "3. Advanced filtering techniques\n",
    "4. Feature extraction and classification\n",
    "5. Performance evaluation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Import our custom modules\n",
    "from main import SemiconImageProcessor\n",
    "from image_utils import MLXImageUtils, AdvancedFilters\n",
    "from config import *\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3a8c6",
   "metadata": {},
   "source": [
    "## 1. Initialize the Image Processor\n",
    "\n",
    "Let's start by initializing our main image processing class with a specific random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca60aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the processor\n",
    "processor = SemiconImageProcessor(seed=42)\n",
    "print(f\"Initialized processor with image size: {processor.image_size}\")\n",
    "print(f\"Will generate {processor.num_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e9069",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Images\n",
    "\n",
    "Generate a dataset of synthetic grayscale images containing random rectangles with varying properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic images\n",
    "images, labels = processor.generate_synthetic_images()\n",
    "\n",
    "print(f\"Generated {len(images)} images\")\n",
    "print(f\"Image shape: {images.shape}\")\n",
    "print(f\"Label distribution: {np.bincount(np.array(labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a922ef8",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Images\n",
    "\n",
    "Let's look at some sample images to understand what we've generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75687cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Convert MLX arrays to numpy for visualization\n",
    "images_np = np.array(images, dtype=np.uint8)\n",
    "labels_np = np.array(labels)\n",
    "\n",
    "# Sample 8 random images\n",
    "sample_indices = np.random.choice(len(images_np), 8, replace=False)\n",
    "label_names = ['No Special Features', 'Large or Thick', 'Large and Thick']\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(images_np[idx], cmap='gray')\n",
    "    ax.set_title(f'Image {idx}\\nLabel: {label_names[labels_np[idx]]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c41f5",
   "metadata": {},
   "source": [
    "## 4. Apply Gaussian Blur\n",
    "\n",
    "Apply Gaussian blur filtering to the images and compare with originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529bc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian blur\n",
    "blurred_images = processor.apply_gaussian_blur(kernel_size=7, sigma=1.5)\n",
    "\n",
    "print(f\"Applied Gaussian blur to {len(blurred_images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs blurred images\n",
    "fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "\n",
    "blurred_np = np.array(blurred_images, dtype=np.uint8)\n",
    "sample_indices = np.random.choice(len(images_np), 6, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    # Original image\n",
    "    axes[0, i].imshow(images_np[idx], cmap='gray')\n",
    "    axes[0, i].set_title(f'Original {idx}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Blurred image\n",
    "    axes[1, i].imshow(blurred_np[idx], cmap='gray')\n",
    "    axes[1, i].set_title(f'Blurred {idx}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f6123",
   "metadata": {},
   "source": [
    "## 5. Advanced Image Filtering\n",
    "\n",
    "Demonstrate various advanced filtering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6068ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a test image for advanced filtering\n",
    "test_idx = 42\n",
    "test_image = images_np[test_idx]\n",
    "\n",
    "# Initialize advanced filters\n",
    "filters = AdvancedFilters()\n",
    "\n",
    "# Apply different filters\n",
    "grad_x, grad_y = filters.sobel_edge_detection(test_image)\n",
    "edge_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "sharpened = filters.laplacian_sharpening(test_image, strength=0.8)\n",
    "threshold = filters.adaptive_threshold(test_image, block_size=11)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(test_image, cmap='gray')\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(edge_magnitude, cmap='gray')\n",
    "axes[0, 1].set_title('Edge Detection (Sobel)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(sharpened, cmap='gray')\n",
    "axes[0, 2].set_title('Laplacian Sharpening')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(threshold, cmap='gray')\n",
    "axes[1, 0].set_title('Adaptive Threshold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(grad_x, cmap='gray')\n",
    "axes[1, 1].set_title('Gradient X')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(grad_y, cmap='gray')\n",
    "axes[1, 2].set_title('Gradient Y')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e187fe",
   "metadata": {},
   "source": [
    "## 6. Feature Extraction\n",
    "\n",
    "Extract features from the images using various kernels and statistical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d22cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "print(\"Extracting features...\")\n",
    "features = processor.extract_features(images)\n",
    "\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "print(f\"Number of features per image: {features.shape[1]}\")\n",
    "\n",
    "# Convert to numpy for analysis\n",
    "features_np = np.array(features)\n",
    "\n",
    "# Show feature statistics\n",
    "feature_names = [\n",
    "    'mean', 'std', 'max', 'min',\n",
    "    'edge_x_mean', 'edge_x_std',\n",
    "    'edge_y_mean', 'edge_y_std',\n",
    "    'blur_mean', 'blur_std',\n",
    "    'sharp_mean', 'sharp_std',\n",
    "    'strong_edges', 'bright_pixels',\n",
    "    'q25', 'q75'\n",
    "]\n",
    "\n",
    "# Create feature statistics dataframe\n",
    "feature_stats = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean': np.mean(features_np, axis=0),\n",
    "    'Std': np.std(features_np, axis=0),\n",
    "    'Min': np.min(features_np, axis=0),\n",
    "    'Max': np.max(features_np, axis=0)\n",
    "})\n",
    "\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(feature_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdc376",
   "metadata": {},
   "source": [
    "## 7. Train Classifier\n",
    "\n",
    "Train a Random Forest classifier using the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "print(\"Training classifier...\")\n",
    "results = processor.train_classifier(features, labels, test_size=0.2)\n",
    "\n",
    "print(f\"\\nClassifier Performance:\")\n",
    "print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"Precision: {results['precision']:.4f}\")\n",
    "print(f\"Recall: {results['recall']:.4f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(results['classification_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999c829",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis\n",
    "\n",
    "Analyze which features are most important for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dfc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the trained classifier\n",
    "classifier = results['classifier']\n",
    "feature_importance = classifier.feature_importances_\n",
    "\n",
    "# Create feature importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance for Rectangle Classification')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 Most Important Features:\")\n",
    "print(importance_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec04a2",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix Analysis\n",
    "\n",
    "Analyze the confusion matrix to understand classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c211f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(results['y_test'], results['y_pred'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_names,\n",
    "            yticklabels=label_names)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"Class {i} ({label_names[i]}) Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30930cf",
   "metadata": {},
   "source": [
    "## 10. Performance Analysis by Image Properties\n",
    "\n",
    "Analyze how different image properties affect classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99595155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature distributions by class\n",
    "test_indices = np.arange(len(results['y_test']))\n",
    "test_features = results['X_test']\n",
    "test_labels = results['y_test']\n",
    "\n",
    "# Create feature analysis plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot distributions for key features\n",
    "key_features = [0, 4, 12, 13]  # mean, edge_x_mean, strong_edges, bright_pixels\n",
    "key_names = ['Image Mean', 'Edge X Mean', 'Strong Edges', 'Bright Pixels']\n",
    "\n",
    "for i, (feat_idx, feat_name) in enumerate(zip(key_features, key_names)):\n",
    "    ax = axes[i//2, i%2]\n",
    "    \n",
    "    for class_label in range(3):\n",
    "        class_mask = test_labels == class_label\n",
    "        class_features = test_features[class_mask, feat_idx]\n",
    "        \n",
    "        ax.hist(class_features, alpha=0.7, label=label_names[class_label], bins=20)\n",
    "    \n",
    "    ax.set_xlabel(feat_name)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{feat_name} Distribution by Class')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5be5c",
   "metadata": {},
   "source": [
    "## 11. Save Results and Data\n",
    "\n",
    "Save all generated data and results for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443111b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results\n",
    "csv_path = processor.evaluate_performance(results)\n",
    "print(f\"Evaluation results saved to: {csv_path}\")\n",
    "\n",
    "# Save all data\n",
    "processor.save_data()\n",
    "print(\"All data saved successfully!\")\n",
    "\n",
    "# Create a summary report\n",
    "summary = {\n",
    "    'Total Images': len(images),\n",
    "    'Image Size': processor.image_size,\n",
    "    'Classes': len(np.unique(labels_np)),\n",
    "    'Features': features.shape[1],\n",
    "    'Test Accuracy': results['accuracy'],\n",
    "    'Test Precision': results['precision'],\n",
    "    'Test Recall': results['recall']\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ffb00e",
   "metadata": {},
   "source": [
    "## 12. Interactive Parameter Exploration\n",
    "\n",
    "Experiment with different parameters to see their effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different blur parameters\n",
    "blur_params = [(3, 0.5), (5, 1.0), (7, 1.5), (9, 2.0)]\n",
    "test_img_idx = 50\n",
    "test_img = images_np[test_img_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(blur_params) + 1, figsize=(20, 4))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(test_img, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Apply different blur parameters\n",
    "for i, (kernel_size, sigma) in enumerate(blur_params):\n",
    "    blurred = cv2.GaussianBlur(test_img, (kernel_size, kernel_size), sigma)\n",
    "    axes[i+1].imshow(blurred, cmap='gray')\n",
    "    axes[i+1].set_title(f'Blur: k={kernel_size}, σ={sigma}')\n",
    "    axes[i+1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbcc25c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated a complete computer vision pipeline for semiconductor analysis including:\n",
    "\n",
    "1. ✅ **Synthetic Data Generation**: Created 512 grayscale images with geometric patterns\n",
    "2. ✅ **GPU Acceleration**: Leveraged MLX for efficient processing on Apple Silicon\n",
    "3. ✅ **Advanced Filtering**: Applied Gaussian blur, edge detection, and morphological operations\n",
    "4. ✅ **Feature Extraction**: Used multiple kernels to extract meaningful features\n",
    "5. ✅ **Classification**: Trained a Random Forest classifier with strong performance\n",
    "6. ✅ **Evaluation**: Comprehensive analysis with multiple metrics\n",
    "7. ✅ **Visualization**: Interactive plots for understanding results\n",
    "8. ✅ **Data Management**: Automated saving and organization of results\n",
    "\n",
    "The pipeline successfully classifies rectangles based on their size and border properties with high accuracy, demonstrating the effectiveness of combining traditional computer vision techniques with modern GPU acceleration."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
